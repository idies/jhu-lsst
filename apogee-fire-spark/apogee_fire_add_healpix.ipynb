{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'numExecutors': 50, 'executorCores': 3, 'executorMemory': '8gb', 'driverMemory': '2g', 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "No active sessions."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"numExecutors\": 50, \"executorCores\": 3, \"executorMemory\": \"8gb\", \"driverMemory\": \"2g\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1</td><td>application_1637717202829_0002</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"/application_1637717202829_0002\">Link</a></td><td><a target=\"_blank\" href=\"http://worker-5.worker.spark.svc.cluster.local:8042/node/containerlogs/container_1637717202829_0002_01_000001/arik\">Link</a></td><td>arik</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import healpy\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import LongType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fire = spark.read.parquet('hdfs:///data/apogee_fire/m12f_lsr0/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function healpix at 0x7efcd1e53ca0>"
     ]
    }
   ],
   "source": [
    "def healpix(nside: pd.Series, ra: pd.Series, dec: pd.Series) -> pd.Series:\n",
    "    theta = np.pi/2 - np.radians(dec.array)\n",
    "    phi = np.radians(ra.array)\n",
    "    nside = nside.iloc[0]\n",
    "    return pd.Series(healpy.ang2pix(nside, theta, phi, nest=True))\n",
    "\n",
    "healpix_udf = pandas_udf(healpix, returnType=LongType())\n",
    "spark.udf.register('healpix', healpix_udf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fire.createOrReplaceTempView('fire')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with_hp = spark.sql('''\n",
    "SELECT *, healpix(8, ra, dec) as hp8, healpix(64, ra, dec) as hp64\n",
    "FROM fire\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "601849c6f54840e990e35bb6b4d81c97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with_hp.write.mode('overwrite').format('parquet') \\\n",
    "    .partitionBy('hp8') \\\n",
    "    .saveAsTable('apogee_fire_m12f_lsr0', path='hdfs:///user/arik/apogee_fire_m12f_lsr0_p-withhp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radecbin = spark.sql('''\n",
    "SELECT ra, dec, count(*) FROM \n",
    "(SELECT CAST(ra AS INT) ra, CAST(dec AS INT) dec FROM fire)\n",
    "GROUP BY ra, dec''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radecbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hexbin(radecbin['ra'], radecbin['dec'], C=radecbin['count(1)'], bins='log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_hp.createOrReplaceTempView('with_hp8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp8bin = spark.sql('''SELECT hp8, count(*) N from with_hp8 GROUP BY hp8 ORDER BY hp8 ASC''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fhp.createOrReplaceTempView('fhp')\n",
    "hp8bin = spark.sql('''SELECT hp8, count(*) N from fhp GROUP BY hp8 ORDER BY hp8 ASC''').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import healpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "healpy.visufunc.mollview(hp8bin['N'], nest=True, norm='log')\n",
    "healpy.graticule(coord='E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Interpreter died:\n",
      "\n",
      "/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/pyspark.zip/pyspark/context.py:264: RuntimeWarning: Failed to add file [file:///opt/spark/python/lib/pyspark.zip] specified in 'spark.submit.pyFiles' to Python path:\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/spark-b99172fc-bb4d-4fb8-879f-d9cb7931d37f/userFiles-6538335a-b9a0-48c0-a27f-110f59d37be4\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/pyspark.zip\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/py4j-0.10.9-src.zip\n",
      "  /usr/lib/python39.zip\n",
      "  /usr/lib/python3.9\n",
      "  /usr/lib/python3.9/lib-dynload\n",
      "  /usr/local/lib/python3.9/dist-packages\n",
      "  /usr/lib/python3/dist-packages\n",
      "  warnings.warn(\n",
      "/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/pyspark.zip/pyspark/context.py:264: RuntimeWarning: Failed to add file [file:///opt/spark/python/lib/py4j-0.10.9-src.zip] specified in 'spark.submit.pyFiles' to Python path:\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/spark-b99172fc-bb4d-4fb8-879f-d9cb7931d37f/userFiles-6538335a-b9a0-48c0-a27f-110f59d37be4\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/pyspark.zip\n",
      "  /tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/py4j-0.10.9-src.zip\n",
      "  /usr/lib/python39.zip\n",
      "  /usr/lib/python3.9\n",
      "  /usr/lib/python3.9/lib-dynload\n",
      "  /usr/local/lib/python3.9/dist-packages\n",
      "  /usr/lib/python3/dist-packages\n",
      "  warnings.warn(\n",
      "\n",
      "ERROR:fake_shell:execute_reply\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 224, in execute\n",
      "    exec(code, global_dict)\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "NameError: name 'healpy' is not defined\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 318, in execute_request\n",
      "    result = node.execute()\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 233, in execute\n",
      "    raise ExecutionError(sys.exc_info())\n",
      "ExecutionError: (<class 'NameError'>, NameError(\"name 'healpy' is not defined\"), <traceback object at 0x7fecd43c5e00>)\n",
      "ERROR:fake_shell:execute_reply\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 497, in magic_matplot\n",
      "    value = global_dict[name]\n",
      "KeyError: 'plt'\n",
      "WARNING:matplotlib:Matplotlib created a temporary config/cache directory at /tmp/matplotlib-08ly3gxh because the default path (/home/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n",
      "WARNING:healpy:0.0 180.0 -180.0 180.0\n",
      "ERROR:fake_shell:execute_reply\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 497, in magic_matplot\n",
      "    value = global_dict[name]\n",
      "KeyError: 'plt'\n",
      "WARNING:healpy:0.0 180.0 -180.0 180.0\n",
      "ERROR:fake_shell:execute_reply\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 497, in magic_matplot\n",
      "    value = global_dict[name]\n",
      "KeyError: 'plt'\n",
      "ERROR:fake_shell:execute_reply\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 497, in magic_matplot\n",
      "    value = global_dict[name]\n",
      "KeyError: 'plt'\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 714, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 686, in main\n",
      "    response = handler(content)\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 318, in execute_request\n",
      "    result = node.execute()\n",
      "  File \"/tmp/nm-local-dir/usercache/arik/appcache/application_1637717202829_0001/container_1637717202829_0001_01_000001/tmp/5688556754557172417\", line 257, in execute\n",
      "    return handler(*self.rest)\n",
      "TypeError: magic_matplot() missing 1 required positional argument: 'name'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%matplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hp32bin = spark.sql('''SELECT hp64, count(*) N from (SELECT healpix(32, ra, dec) as hp64 FROM fire) GROUP BY hp64 ORDER BY hp64 ASC''').toPandas()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  },
  "sciserver": {
   "copySource": {
    "path": "apogee-fire-to-parquet",
    "volId": "49850",
    "volType": "uservolumes"
   },
   "imageInfo": {
    "cachedContainer": {
     "arik": 113863
    },
    "dataVolumes": [],
    "domain": 6,
    "name": "Dracula Spark",
    "userVolumes": [
     49850,
     49851
    ]
   },
   "lastEdit": {
    "time": 1638202221654,
    "user": "arik"
   },
   "notebookId": "YXJpazE2MzU0NDYzMzgwOTU="
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "47.6px",
    "left": "1237px",
    "top": "107.8px",
    "width": "159px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
