{
    "metadata": {
        "kernelspec": {
            "name": "pysparkkernel",
            "display_name": "PySpark"
        },
        "language_info": {
            "name": "pyspark",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "python",
                "version": 2
            },
            "pygments_lexer": "python2"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Spark sample showing read/write methods\n",
                "In this sample notebook, we will read CSV file from HDFS, write it as parquet file and save a Hive table definition. We will also run some Spark SQL commands using the Hive table.\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "e44c70a1-1da6-421f-ba41-80c6f46a6142"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "%%configure -f\r\n",
                "{\"executorMemory\": \"58g\", \"executorCores\": 30, \"numExecutors\":4}\r\n",
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "9dee9ba6-570d-4ffe-87fa-2d3fa693c839"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "for item in sorted(sc._conf.getAll()): print(item)\r\n",
                "# vanilla:\r\n",
                "#('spark.livy.spark_major_version', '2')\r\n",
                "#('spark.master', 'yarn')"
            ],
            "metadata": {
                "azdata_cell_guid": "f9a600de-c896-46f0-8281-62ccddbbba30"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "# this one doesn't work, don't use it.\r\n",
                "# jvv: Meet's schema, tweaked for with UC's sql<->parquet data type mappings for stuff like INTs and BITs\r\n",
                "# SQL BIT as parquet booleans here\r\n",
                "from pyspark.sql.types import *\r\n",
                "\r\n",
                "# Source:\r\n",
                "customSchemabool= StructType([ \r\n",
                "      StructField(\"id\", LongType(), True),\r\n",
                "      StructField(\"chunkid\", IntegerType(), True),\r\n",
                "      StructField(\"coord_ra\", DoubleType(), True),\r\n",
                "      StructField(\"coord_decl\", DoubleType(), True),\r\n",
                "      StructField(\"coord_htmId20\", LongType(), True),\r\n",
                "      StructField(\"parent\", LongType(), True),\r\n",
                "      StructField(\"flags_badcentroid\", BooleanType(), True),\r\n",
                "      StructField(\"centroid_sdss_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_y\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_flags\", BooleanType(), True),\r\n",
                "      StructField(\"flags_pixel_edge\", BooleanType(), True),\r\n",
                "      StructField(\"flags_pixel_interpolated_any\", BooleanType(), True),\r\n",
                "      StructField(\"flags_pixel_interpolated_center\", BooleanType(), True),\r\n",
                "      StructField(\"flags_pixel_saturated_any\", BooleanType(), True),\r\n",
                "      StructField(\"flags_pixel_saturated_center\", BooleanType(), True),\r\n",
                "      StructField(\"flags_pixel_cr_any\", BooleanType(), True),\r\n",
                "      StructField(\"flags_pixel_cr_center\", BooleanType(), True),\r\n",
                "      StructField(\"centroid_naive_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_y\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_flags\", BooleanType(), True),\r\n",
                "      StructField(\"centroid_gaussian_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_y\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_flags\", BooleanType(), True),\r\n",
                "      StructField(\"shape_sdss_Ixx\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_Iyy\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_Ixy\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxxVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxxIyyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxxIxyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IyyVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IyyIxyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxyVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_flags\", BooleanType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_x\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_y\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_flags\", BooleanType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_unweightedbad\", BooleanType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_unweighted\", BooleanType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_shift\", BooleanType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_maxiter\", BooleanType(), True),\r\n",
                "      StructField(\"flux_psf\", DoubleType(), True),\r\n",
                "      StructField(\"flux_psf_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_psf_flags\", BooleanType(), True),\r\n",
                "      StructField(\"flux_psf_psffactor\", DoubleType(), True),\r\n",
                "      StructField(\"flux_psf_flags_psffactor\", BooleanType(), True),\r\n",
                "      StructField(\"flux_psf_flags_badcorr\", BooleanType(), True),\r\n",
                "      StructField(\"flux_naive\", DoubleType(), True),\r\n",
                "      StructField(\"flux_naive_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_naive_flags\", BooleanType(), True),\r\n",
                "      StructField(\"flux_gaussian\", DoubleType(), True),\r\n",
                "      StructField(\"flux_gaussian_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_gaussian_flags\", BooleanType(), True),\r\n",
                "      StructField(\"flux_gaussian_psffactor\", DoubleType(), True),\r\n",
                "      StructField(\"flux_gaussian_flags_psffactor\", BooleanType(), True),\r\n",
                "      StructField(\"flux_gaussian_flags_badcorr\", BooleanType(), True),\r\n",
                "      StructField(\"flux_sinc\", DoubleType(), True),\r\n",
                "      StructField(\"flux_sinc_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_sinc_flags\", BooleanType(), True),\r\n",
                "      StructField(\"centroid_record_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_record_y\", DoubleType(), True),\r\n",
                "      StructField(\"classification_extendedness\", DoubleType(), True),\r\n",
                "      StructField(\"aperturecorrection\", DoubleType(), True),\r\n",
                "      StructField(\"aperturecorrection_err\", DoubleType(), True),\r\n",
                "      StructField(\"refFlux\", DoubleType(), True),\r\n",
                "      StructField(\"refFlux_err\", DoubleType(), True),\r\n",
                "      StructField(\"objectId\", LongType(), True),\r\n",
                "      StructField(\"coord_raVar\", DoubleType(), True),\r\n",
                "      StructField(\"coord_radeclCov\", DoubleType(), True),\r\n",
                "      StructField(\"coord_declVar\", DoubleType(), True),\r\n",
                "      StructField(\"exposure_id\", LongType(), True),\r\n",
                "      StructField(\"exposure_filter_id\", IntegerType(), True),\r\n",
                "      StructField(\"exposure_time\", DoubleType(), True),\r\n",
                "      StructField(\"exposure_time_mid\", DoubleType(), True),\r\n",
                "      StructField(\"cluster_id\", LongType(), True),\r\n",
                "      StructField(\"cluster_coord_ra\", DoubleType(), True),\r\n",
                "      StructField(\"cluster_coord_decl\", DoubleType(), True),\r\n",
                "\r\n",
                "\r\n",
                "]) \r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "115b7bb1-b801-40c2-9a8c-d3a055f347f4"
            },
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": [
                "# sue: THIS IS THE ONE THAT WORKS\r\n",
                "# jvv: Meet's schema, tweaked for with UC's sql<->parquet data type mappings for stuff like INTs and BITs\r\n",
                "# except SQL BITs as parquet int32s\r\n",
                "from pyspark.sql.types import *\r\n",
                "\r\n",
                "# Source:\r\n",
                "customSchemaint= StructType([ \r\n",
                "      StructField(\"id\", LongType(), True),\r\n",
                "      StructField(\"chunkid\", IntegerType(), True),\r\n",
                "      StructField(\"coord_ra\", DoubleType(), True),\r\n",
                "      StructField(\"coord_decl\", DoubleType(), True),\r\n",
                "      StructField(\"coord_htmId20\", LongType(), True),\r\n",
                "      StructField(\"parent\", LongType(), True),\r\n",
                "      StructField(\"flags_badcentroid\", IntegerType(), True),\r\n",
                "      StructField(\"centroid_sdss_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_y\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_sdss_flags\", IntegerType(), True),\r\n",
                "      StructField(\"flags_pixel_edge\", IntegerType(), True),\r\n",
                "      StructField(\"flags_pixel_interpolated_any\", IntegerType(), True),\r\n",
                "      StructField(\"flags_pixel_interpolated_center\", IntegerType(), True),\r\n",
                "      StructField(\"flags_pixel_saturated_any\", IntegerType(), True),\r\n",
                "      StructField(\"flags_pixel_saturated_center\", IntegerType(), True),\r\n",
                "      StructField(\"flags_pixel_cr_any\", IntegerType(), True),\r\n",
                "      StructField(\"flags_pixel_cr_center\", IntegerType(), True),\r\n",
                "      StructField(\"centroid_naive_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_y\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_naive_flags\", IntegerType(), True),\r\n",
                "      StructField(\"centroid_gaussian_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_y\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_gaussian_flags\", IntegerType(), True),\r\n",
                "      StructField(\"shape_sdss_Ixx\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_Iyy\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_Ixy\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxxVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxxIyyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxxIxyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IyyVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IyyIxyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_IxyVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_flags\", IntegerType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_x\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_y\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_xVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_xyCov\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_yVar\", DoubleType(), True),\r\n",
                "      StructField(\"shape_sdss_centroid_flags\", IntegerType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_unweightedbad\", IntegerType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_unweighted\", IntegerType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_shift\", IntegerType(), True),\r\n",
                "      StructField(\"shape_sdss_flags_maxiter\", IntegerType(), True),\r\n",
                "      StructField(\"flux_psf\", DoubleType(), True),\r\n",
                "      StructField(\"flux_psf_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_psf_flags\", IntegerType(), True),\r\n",
                "      StructField(\"flux_psf_psffactor\", DoubleType(), True),\r\n",
                "      StructField(\"flux_psf_flags_psffactor\", IntegerType(), True),\r\n",
                "      StructField(\"flux_psf_flags_badcorr\", IntegerType(), True),\r\n",
                "      StructField(\"flux_naive\", DoubleType(), True),\r\n",
                "      StructField(\"flux_naive_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_naive_flags\", IntegerType(), True),\r\n",
                "      StructField(\"flux_gaussian\", DoubleType(), True),\r\n",
                "      StructField(\"flux_gaussian_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_gaussian_flags\", IntegerType(), True),\r\n",
                "      StructField(\"flux_gaussian_psffactor\", DoubleType(), True),\r\n",
                "      StructField(\"flux_gaussian_flags_psffactor\", IntegerType(), True),\r\n",
                "      StructField(\"flux_gaussian_flags_badcorr\", IntegerType(), True),\r\n",
                "      StructField(\"flux_sinc\", DoubleType(), True),\r\n",
                "      StructField(\"flux_sinc_err\", DoubleType(), True),\r\n",
                "      StructField(\"flux_sinc_flags\", IntegerType(), True),\r\n",
                "      StructField(\"centroid_record_x\", DoubleType(), True),\r\n",
                "      StructField(\"centroid_record_y\", DoubleType(), True),\r\n",
                "      StructField(\"classification_extendedness\", DoubleType(), True),\r\n",
                "      StructField(\"aperturecorrection\", DoubleType(), True),\r\n",
                "      StructField(\"aperturecorrection_err\", DoubleType(), True),\r\n",
                "      StructField(\"refFlux\", DoubleType(), True),\r\n",
                "      StructField(\"refFlux_err\", DoubleType(), True),\r\n",
                "      StructField(\"objectId\", LongType(), True),\r\n",
                "      StructField(\"coord_raVar\", DoubleType(), True),\r\n",
                "      StructField(\"coord_radeclCov\", DoubleType(), True),\r\n",
                "      StructField(\"coord_declVar\", DoubleType(), True),\r\n",
                "      StructField(\"exposure_id\", LongType(), True),\r\n",
                "      StructField(\"exposure_filter_id\", IntegerType(), True),\r\n",
                "      StructField(\"exposure_time\", DoubleType(), True),\r\n",
                "      StructField(\"exposure_time_mid\", DoubleType(), True),\r\n",
                "      StructField(\"cluster_id\", LongType(), True),\r\n",
                "      StructField(\"cluster_coord_ra\", DoubleType(), True),\r\n",
                "      StructField(\"cluster_coord_decl\", DoubleType(), True),\r\n",
                "\r\n",
                "\r\n",
                "]) \r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "1328083e-1583-4f6f-8b1c-131982fddeda"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Starting Spark application\n",
                    "output_type": "stream"
                },
                {
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>35</td><td>application_1580142637008_0036</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"https://172.23.25.61:30443/gateway/default/yarn/proxy/application_1580142637008_0036/\">Link</a></td><td><a target=\"_blank\" href=\"https://172.23.25.61:30443/gateway/default/yarn/container/container_1580142637008_0036_01_000001/root\">Link</a></td><td>✔</td></tr></table>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "4c29dd552b6645e89b42cb08f0047284"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "SparkSession available as 'spark'.\n",
                    "output_type": "stream"
                },
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "3f2b6526645e4bb78735025e57a5d171"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "# sue's test to make parquet files close to 1GB in size\r\n",
                "dfsue = spark.read.load('/LSST/csv/test/Source', format=\"csv\", sep=',', schema=customSchemaint)\r\n",
                "dfsue.show(2)"
            ],
            "metadata": {
                "azdata_cell_guid": "d6c1dbc4-a50e-4f26-b57e-c543ea064f8a"
            },
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "code",
            "source": [
                "#df1 = spark.read.load('/LSST/Source/csv/', format=\"csv\", sep=';', schema=customSchema, header=\"true\")\r\n",
                "#df1 = spark.read.load('/LSST/Source/csv/Source_8945.csv', format=\"csv\", sep=';' , schema=customSchema)\r\n",
                "#df1 = spark.read.load('/LSST/Source/csv/Source_8945.csv', format=\"csv\", sep=';', inferSchema=\"true\", header=\"true\")\r\n",
                "#df1 = spark.read.load('/LSST/Source/csv/Source_8945.csv', format=\"csv\", sep=';', schema=customSchema, header=\"true\")\r\n",
                "\r\n",
                "#df1 = spark.read.load('/LSST/csv/Source', format=\"csv\", sep=',', schema=customSchemaint)\r\n",
                "#df1 = spark.read.load('/LSST/sue/csv/Source/Source_9659.csv', format=\"csv\", sep=',', inferSchema=\"true\")\r\n",
                "df1 = spark.read.load('/LSST/csv/Source/Source_9659.csv', format=\"csv\", sep=',', schema=customSchemaint)\r\n",
                "#df1 = spark.read.load('/LSST/jvv/Source_9659_id-chunkid-coord_ra.csv', format=\"csv\", sep=',', schema=customSchema)\r\n",
                "#df1 = spark.read.load('/LSST/jvv/csv/Source', format=\"csv\", sep=',', schema=customSchema)\r\n",
                "#df1 = spark.read.load('/LSST/jvv/test', format=\"csv\", sep=',', schema=customSchema)\r\n",
                "\r\n",
                "\r\n",
                "# Aris sample, not identical to Meet's:\r\n",
                "'''\r\n",
                "results = spark.read.option(\"inferSchema\", \"true\").csv('/clickstream_data').toDF(\r\n",
                "            \"wcs_click_date_sk\", \"wcs_click_time_sk\", \"wcs_sales_sk\", \"wcs_item_sk\", \"wcs_web_page_sk\", \"wcs_user_sk\"\r\n",
                "            )\r\n",
                "'''\r\n",
                "\r\n",
                "#df1.printSchema()\r\n",
                "df1.show(2)"
            ],
            "metadata": {
                "azdata_cell_guid": "e6edbb7f-a388-419f-8f39-20f8decdc904"
            },
            "outputs": [
                {
                    "data": {
                        "text/plain": "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…",
                        "application/vnd.jupyter.widget-view+json": {
                            "version_major": 2,
                            "version_minor": 0,
                            "model_id": "64c36a87bac94be5a938cdb75c122146"
                        }
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "dfsue.coalesce(12).write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"source_test_parquet\")"
            ],
            "metadata": {
                "azdata_cell_guid": "69f2f9bd-0bce-4772-a342-bd86d9ecd68d"
            },
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": [
                "#df1.coalesce(350).write.parquet(\"/user/hive/warehouse/source/\", mode='overwrite')\r\n",
                "\r\n",
                "# Meet above v. Aris sample:\r\n",
                "# results.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"web_clickstreams\")\r\n",
                "# this will write the default number of files (lots of small files)\r\n",
                "df1.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"Source\")\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "7be5980d-f816-4ca8-9272-b73f0b971a82"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "# attempt to write 6000 parquet files from csv\r\n",
                "import datetime\r\n",
                "\r\n",
                "before = datetime.datetime.now()\r\n",
                "# coalesce stuff into 6000 files \r\n",
                "\r\n",
                "df1.coalesce(6000).write.parquet(\"/user/hive/warehouse/source_new\", mode='overwrite')\r\n",
                "## 15h\r\n",
                "\r\n",
                "after = datetime.datetime.now()\r\n",
                "print (after - before )"
            ],
            "metadata": {
                "azdata_cell_guid": "c84dd6bc-181c-453c-9371-aef97a5ce728"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "14b39de7-fa87-4449-8d06-c0a0414dbc27"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "df1.printSchema()"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "f657ad25-b2b4-4171-8808-b4e59a704e59"
            },
            "outputs": [],
            "execution_count": 11
        },
        {
            "cell_type": "code",
            "source": [
                "# Disable saving SUCCESS file\r\n",
                "sc._jsc.hadoopConfiguration().set(\"mapreduce.fileoutputcommitter.marksuccessfuljobs\", \"false\") \r\n",
                "\r\n",
                "# Print the current warehouse directory where the parquet files will be stored\r\n",
                "print(spark.conf.get(\"spark.sql.warehouse.dir\"))\r\n",
                "\r\n",
                "# Save results as parquet file and create hive table\r\n",
                "results.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"web_clickstreams\")\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "0b306b92-6825-43e1-8aa8-815bd7d55d42"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "import datetime\r\n",
                "\r\n",
                "before = datetime.datetime.now()\r\n",
                "\r\n",
                "\r\n",
                "# Execute Spark SQL commands\r\n",
                "#sqlDF = spark.sql(\"SELECT * FROM Source LIMIT 100\")\r\n",
                "\r\n",
                "#sqlDF = spark.sql(\"SELECT * FROM Source LIMIT 100\")\r\n",
                "#sqlDF = spark.sql(\"select min(coord_ra) from Source\")\r\n",
                "#sqlDF = spark.sql(\"SELECT count(*)  FROM Source where flux_sinc between 1 and 1.1\")\r\n",
                "sqlDF = spark.sql(\"select id from source limit 10\")\r\n",
                "\r\n",
                "#sqlDF = spark.sql(\"select * from sourcesue limit 100\")\r\n",
                "\r\n",
                "\r\n",
                "sqlDF.show()\r\n",
                "after = datetime.datetime.now()\r\n",
                "print (after - before )\r\n",
                "\r\n",
                "#sqlDF = spark.sql(\"SELECT wcs_user_sk, COUNT(*)\\\r\n",
                "#                     FROM web_clickstreams\\\r\n",
                "#                    WHERE wcs_user_sk IS NOT NULL\\\r\n",
                "#                   GROUP BY wcs_user_sk\\\r\n",
                "#                   ORDER BY COUNT(*) DESC LIMIT 100\")\r\n",
                "#sqlDF.show()"
            ],
            "metadata": {
                "azdata_cell_guid": "50fbc940-3032-4624-9302-aa241aa3c281"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "# sue's attempt to read a dir of parquet files into a dataframe\r\n",
                "df = spark.read.load(\"/user/hive/warehouse/source_new\")\r\n",
                "#df = spark.read.load(\"/user/hive/warehouse/sourcesue\")"
            ],
            "metadata": {
                "azdata_cell_guid": "6c71e359-c15f-4107-83b2-634c8256497f"
            },
            "outputs": [],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": [
                "df.write.saveAsTable(\"source\")"
            ],
            "metadata": {
                "azdata_cell_guid": "2f0f4413-faaa-4cc8-9ffb-011b5017a127"
            },
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": [
                "import datetime\r\n",
                "\r\n",
                "before = datetime.datetime.now()\r\n",
                "# coalesce stuff into 6000 files \r\n",
                "\r\n",
                "df.coalesce(6).write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"source_new\")\r\n",
                "\r\n",
                "after = datetime.datetime.now()\r\n",
                "print (after - before )\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "d9d30919-9ca2-4fdd-97ba-b19d8a7de368"
            },
            "outputs": [],
            "execution_count": 4
        },
        {
            "cell_type": "code",
            "source": [
                "import datetime\r\n",
                "\r\n",
                "before = datetime.datetime.now()\r\n",
                "time.sleep(1)\r\n",
                "after = datetime.datetime.now()\r\n",
                "print (after - before )"
            ],
            "metadata": {
                "azdata_cell_guid": "6dfde73c-8df4-4f63-9f4e-a4be8fa0b8b4"
            },
            "outputs": [],
            "execution_count": 16
        },
        {
            "cell_type": "code",
            "source": [
                "import pyspark\r\n",
                "\r\n",
                "# start\r\n",
                "sc = pyspark.SparkContext()\r\n",
                "\r\n",
                "#stop\r\n",
                "sc.stop()"
            ],
            "metadata": {
                "azdata_cell_guid": "15023380-8b75-4947-a4c5-6854f87ffa00"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "# Read the product reviews CSV files into a spark data frame, print schema & top rows\r\n",
                "results = spark.read.option(\"inferSchema\", \"true\").csv('/product_review_data').toDF(\r\n",
                "            \"pr_review_sk\", \"pr_review_content\"\r\n",
                "            )\r\n",
                "results.printSchema()\r\n",
                "results.show()"
            ],
            "metadata": {
                "azdata_cell_guid": "650b40b5-f033-4ed1-9cfc-b38218202f3c"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "# Save results as parquet file and create hive table\r\n",
                "results.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"product_reviews\")\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "0a1d5c58-7749-4315-8378-3031288d203b"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "# Execute Spark SQL commands\r\n",
                "sqlDF = spark.sql(\"SELECT pr_review_sk, CHAR_LENGTH(pr_review_content) as len FROM product_reviews LIMIT 100\")\r\n",
                "sqlDF.show()"
            ],
            "metadata": {
                "azdata_cell_guid": "939fbc68-d7c3-40ed-be8a-3d5eee0d782f"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "spark.sql('drop table Source')"
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "b79a98cb-4a96-4ecf-a21d-31b9c866ddf6"
            },
            "outputs": [],
            "execution_count": 10
        },
        {
            "cell_type": "code",
            "source": [
                ""
            ],
            "metadata": {
                "language": "python",
                "azdata_cell_guid": "88ddc0b8-b6b3-44ac-9529-b93d585857a5"
            },
            "outputs": [],
            "execution_count": 1
        }
    ]
}