{
    "metadata": {
        "kernelspec": {
            "name": "pysparkkernel",
            "display_name": "PySpark"
        },
        "language_info": {
            "name": "pyspark",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "python",
                "version": 2
            },
            "pygments_lexer": "python2"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# Read CSV into a data frame\r\n",
                "In this step we read the CSV into a data frame and do some basic cleanup steps. \r\n",
                "\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "26db1e91-0672-43a6-96f7-ef0286c26529"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "#spark = SparkSession.builder.getOrCreate()\r\n",
                "sc.setLogLevel(\"WARN\")\r\n",
                "\r\n",
                "#Read a file and then write it to the SQL table\r\n",
                "datafile = \"/user/hive/warehouse/object_test\"\r\n",
                "df = spark.read.format('parquet').load(datafile)\r\n",
                "df.show(1)\r\n",
                "df.printSchema()"
            ],
            "metadata": {
                "azdata_cell_guid": "a2417b63-2504-447c-8813-e34f9efef10c"
            },
            "outputs": [
{
    "name": "stdout",
    "text": "Starting Spark application\n",
    "output_type": "stream"
}, {
    "name": "stderr",
    "text": "The code failed because of a fatal error:\n\tSession 5 unexpectedly reached final status 'dead'. See logs:\nstdout: \n\nstderr: \n2019-10-07 19:03:19,983 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n2019-10-07 19:03:21,185 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/rsc-jars/livy-api-0.6.64038.jar.\n2019-10-07 19:03:21,185 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/rsc-jars/livy-rsc-0.6.64038.jar.\n2019-10-07 19:03:21,185 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/rsc-jars/netty-all-4.1.17.Final.jar.\n2019-10-07 19:03:21,185 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-api-jdo-3.2.6.jar.\n2019-10-07 19:03:21,185 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-core-3.2.10.jar.\n2019-10-07 19:03:21,185 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-rdbms-3.2.9.jar.\n2019-10-07 19:03:21,185 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/repl_2.11-jars/commons-codec-1.9.jar.\n2019-10-07 19:03:21,186 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/repl_2.11-jars/livy-core_2.11-0.6.64038.jar.\n2019-10-07 19:03:21,186 WARN deploy.DependencyUtils: Skip remote jar hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/repl_2.11-jars/livy-repl_2.11-0.6.64038.jar.\n2019-10-07 19:03:21,288 INFO client.DefaultRMFailoverProxyProvider: Connecting to ResourceManager at sparkhead-0.sparkhead-svc/172.24.39.3:8032\n2019-10-07 19:03:21,497 INFO yarn.Client: Requesting a new application from cluster with 4 NodeManagers\n2019-10-07 19:03:21,580 INFO conf.Configuration: resource-types.xml not found\n2019-10-07 19:03:21,580 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\n2019-10-07 19:03:21,595 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (65536 MB per container)\n2019-10-07 19:03:21,595 INFO yarn.Client: Will allocate AM container, with 2432 MB memory including 384 MB overhead\n2019-10-07 19:03:21,596 INFO yarn.Client: Setting up container launch context for our AM\n2019-10-07 19:03:21,601 INFO yarn.Client: Setting up the launch environment for our AM container\n2019-10-07 19:03:21,610 INFO yarn.Client: Preparing resources for our AM container\n2019-10-07 19:03:21,638 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs:/spark/spark_libs.zip\n2019-10-07 19:03:21,689 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/rsc-jars/livy-api-0.6.64038.jar\n2019-10-07 19:03:21,698 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/rsc-jars/livy-rsc-0.6.64038.jar\n2019-10-07 19:03:21,701 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/rsc-jars/netty-all-4.1.17.Final.jar\n2019-10-07 19:03:21,703 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-api-jdo-3.2.6.jar\n2019-10-07 19:03:21,709 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-core-3.2.10.jar\n2019-10-07 19:03:21,711 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-rdbms-3.2.9.jar\n2019-10-07 19:03:21,713 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/repl_2.11-jars/commons-codec-1.9.jar\n2019-10-07 19:03:21,718 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/repl_2.11-jars/livy-core_2.11-0.6.64038.jar\n2019-10-07 19:03:21,721 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/repl_2.11-jars/livy-repl_2.11-0.6.64038.jar\n2019-10-07 19:03:21,724 WARN yarn.Client: Same name resource file:///opt/spark/jars/datanucleus-api-jdo-3.2.6.jar added multiple times to distributed cache\n2019-10-07 19:03:21,724 WARN yarn.Client: Same name resource file:///opt/spark/jars/datanucleus-core-3.2.10.jar added multiple times to distributed cache\n2019-10-07 19:03:21,724 WARN yarn.Client: Same name resource file:///opt/spark/jars/datanucleus-rdbms-3.2.9.jar added multiple times to distributed cache\n2019-10-07 19:03:21,725 INFO yarn.Client: Uploading resource file:/opt/spark/conf/hive-site.xml -> hdfs://nmnode-0-0.nmnode-0-svc:9000/user/root/.sparkStaging/application_1570231724611_0006/hive-site.xml\n2019-10-07 19:03:22,033 INFO yarn.Client: Source and destination file systems are the same. Not copying hdfs:/livy/sparkr.zip#sparkr\n2019-10-07 19:03:22,039 INFO yarn.Client: Uploading resource file:/opt/spark/python/lib/pyspark.zip -> hdfs://nmnode-0-0.nmnode-0-svc:9000/user/root/.sparkStaging/application_1570231724611_0006/pyspark.zip\n2019-10-07 19:03:22,102 INFO yarn.Client: Uploading resource file:/opt/spark/python/lib/py4j-0.10.7-src.zip -> hdfs://nmnode-0-0.nmnode-0-svc:9000/user/root/.sparkStaging/application_1570231724611_0006/py4j-0.10.7-src.zip\n2019-10-07 19:03:22,136 WARN yarn.Client: Same name resource hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/pyspark.zip added multiple times to distributed cache\n2019-10-07 19:03:22,136 WARN yarn.Client: Same name resource hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/py4j-0.10.7-src.zip added multiple times to distributed cache\n2019-10-07 19:03:22,298 INFO yarn.Client: Uploading resource file:/tmp/spark-d22ff07c-47b2-4d81-b16a-009eaca7d9d2/__spark_conf__1446548044226376092.zip -> hdfs://nmnode-0-0.nmnode-0-svc:9000/user/root/.sparkStaging/application_1570231724611_0006/__spark_conf__.zip\n2019-10-07 19:03:22,368 INFO spark.SecurityManager: Changing view acls to: root\n2019-10-07 19:03:22,369 INFO spark.SecurityManager: Changing modify acls to: root\n2019-10-07 19:03:22,369 INFO spark.SecurityManager: Changing view acls groups to: \n2019-10-07 19:03:22,370 INFO spark.SecurityManager: Changing modify acls groups to: \n2019-10-07 19:03:22,370 INFO spark.SecurityManager: SecurityManager: authentication enabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n2019-10-07 19:03:23,503 INFO yarn.Client: Submitting application application_1570231724611_0006 to ResourceManager\n2019-10-07 19:03:23,554 INFO impl.YarnClientImpl: Submitted application application_1570231724611_0006\n2019-10-07 19:03:23,556 INFO yarn.Client: Application report for application_1570231724611_0006 (state: ACCEPTED)\n2019-10-07 19:03:23,560 INFO yarn.Client: \n\t client token: N/A\n\t diagnostics: [Mon Oct 07 19:03:23 +0000 2019] Application is Activated, waiting for resources to be assigned for AM.  Details : AM Partition = <DEFAULT_PARTITION> ; Partition Resource = <memory:262144, vCores:120> ; Queue's Absolute capacity = 100.0 % ; Queue's Absolute used capacity = 0.0 % ; Queue's Absolute max capacity = 100.0 % ; Queue's capacity (absolute resource) = <memory:262144, vCores:120> ; Queue's used capacity (absolute resource) = <memory:0, vCores:0> ; Queue's max capacity (absolute resource) = <memory:262144, vCores:120> ; \n\t ApplicationMaster host: N/A\n\t ApplicationMaster RPC port: -1\n\t queue: default\n\t start time: 1570475003520\n\t final status: UNDEFINED\n\t tracking URL: https://sparkhead-0.sparkhead-svc:8090/proxy/application_1570231724611_0006/\n\t user: root\n2019-10-07 19:03:23,566 INFO util.ShutdownHookManager: Shutdown hook called\n2019-10-07 19:03:23,567 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-d07b7b02-4f4f-4aea-bfb7-80cfb29b7841\n2019-10-07 19:03:23,572 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-d22ff07c-47b2-4d81-b16a-009eaca7d9d2\n\nYARN Diagnostics: \nApplication application_1570231724611_0006 failed 1 times (global limit =2; local limit is =1) due to AM Container for appattempt_1570231724611_0006_000001 exited with  exitCode: -1000\nFailing this attempt.Diagnostics: [2019-10-07 19:03:23.838]Failed to download resource { { hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-rdbms-3.2.9.jar, 1570474952871, FILE, null },pending,[(container_1570231724611_0006_01_000001)],2234909673490545,DOWNLOADING} java.io.IOException: Resource hdfs://nmnode-0-0.nmnode-0-svc:9000/livy/spark/datanucleus-rdbms-3.2.9.jar changed on src filesystem (expected 1570474952871, was 1570475001991\nFor more detailed output, check the application tracking page: https://sparkhead-0.sparkhead-svc:8090/cluster/app/application_1570231724611_0006 Then click on links to logs of each attempt.\n. Failing the application..\n\nSome things to try:\na) Make sure Spark has enough available resources for Jupyter to create a Spark context.\nb) Contact your Jupyter administrator to make sure the Spark magics library is configured correctly.\nc) Restart the kernel.\n",
    "output_type": "stream"
}
],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "# (PART 2) Write and READ to Data Pool external Tables in Big Data Cluster\r\n",
                "- Write dataframe to SQL external table in Data Pools in Big Data Cluste\r\n",
                "- Read SQL external Table to Spark dataframe"
            ],
            "metadata": {
                "azdata_cell_guid": "eefb6c3c-8d58-4022-9770-5d2f72011c49"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "# Write from Spark to SQL table using MSSQL Spark Connector\r\n",
                "print(\"Use MSSQL connector to write to master SQL instance \")\r\n",
                "\r\n",
                "servername = \"jdbc:sqlserver://master-0.master-svc\"\r\n",
                "dbname = \"LSST\"\r\n",
                "url = servername + \";\" + \"databaseName=\" + dbname + \";\"\r\n",
                "\r\n",
                "\r\n",
                "user = \"sa\"\r\n",
                "password = \"REDACTED\" # Please specify password here\r\n",
                "\r\n",
                "datapool_table = \"Object_test_rr\"\r\n",
                "datasource_name = \"SqlDataPool\"\r\n",
                "\r\n",
                "batchsize = 1000000\r\n",
                "\r\n",
                "\r\n",
                "try:\r\n",
                "  df.write \\\r\n",
                "    .format(\"com.microsoft.sqlserver.jdbc.spark\") \\\r\n",
                "    .mode(\"overwrite\") \\\r\n",
                "    .option(\"url\", url) \\\r\n",
                "    .option(\"dbtable\", datapool_table) \\\r\n",
                "    .option(\"user\", user) \\\r\n",
                "    .option(\"password\", password) \\\r\n",
                "    .option(\"dataPoolDataSource\",datasource_name)\\\r\n",
                "    .option(\"batchsize\",batchsize)\\\r\n",
                "    .save()\r\n",
                "except ValueError as error :\r\n",
                "    print(\"MSSQL Connector write failed\", error)\r\n",
                "\r\n",
                "print(\"MSSQL Connector write(overwrite) to data pool external table succeeded\")\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "c9f95c7e-4d29-4400-8dc7-fb89b7eff210"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "Use MSSQL connector to write to master SQL instance \nMSSQL Connector write(overwrite) to data pool external table succeeded"
                }
            ],
            "execution_count": 4
        }
    ]
}