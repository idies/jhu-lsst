{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>124</td><td>application_1580142637008_0133</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"https://sparkhead-0.sparkhead-svc:8090/proxy/application_1580142637008_0133/\">Link</a></td><td><a target=\"_blank\" href=\"https://storage-0-1.storage-0-svc.filedb.svc.cluster.local:8044/node/containerlogs/container_1580142637008_0133_01_000001/root\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c034065e18314c45af7bc87da4e2cf3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'name': 'remotesparkmagics-sue', 'executorMemory': '12G', 'numExecutors': 10, 'executorCores': 4, 'conf': {'spark.jars': '/system/jar/simpleHTM.jar,/system/jar/jhealpix.jar'}, 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>124</td><td>application_1580142637008_0133</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"https://sparkhead-0.sparkhead-svc:8090/proxy/application_1580142637008_0133/\">Link</a></td><td><a target=\"_blank\" href=\"https://storage-0-1.storage-0-svc.filedb.svc.cluster.local:8044/node/containerlogs/container_1580142637008_0133_01_000001/root\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"name\": \"remotesparkmagics-sue\", \"executorMemory\": \"12G\", \"numExecutors\": 10, \n",
    " \"executorCores\": 4,\n",
    " \"conf\": {\"spark.jars\": \"/system/jar/simpleHTM.jar,/system/jar/jhealpix.jar\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846304f4fb6f4194b13f1ca830ced68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import simple.HTMindex\n",
      "import healpix.jhu.Healpix\n",
      "import org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}\n",
      "import org.apache.spark.sql.functions.udf\n",
      "import java.util.Calendar\n"
     ]
    }
   ],
   "source": [
    "import simple.HTMindex\n",
    "import healpix.jhu.Healpix\n",
    "import org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}\n",
    "import org.apache.spark.sql.functions.udf\n",
    "import java.util.Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab5aeb2b8e3462aa3c53a7e7766b907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined object HTMUtils\n",
      "defined object HEALPixUtils\n"
     ]
    }
   ],
   "source": [
    "object HTMUtils extends Serializable {\n",
    "    var htmindex= new HTMindex() with Serializable\n",
    "    val htmid: (Double, Double) => Long = htmindex.lookupId(_,_)\n",
    "\n",
    "    val htmidUDF=udf(htmid)\n",
    "    \n",
    "}\n",
    "\n",
    "object HEALPixUtils extends Serializable {\n",
    "    var hp = new Healpix() with Serializable\n",
    "    val healpixid: (Double, Double) => Long = hp.ang2pix(_,_)\n",
    "    val healpixidUDF=udf(healpixid)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e31c3edf12436db2a8f735bdd63302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from scala"
     ]
    }
   ],
   "source": [
    "print(\"hello from scala\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# can we get this login thing to work in scala?\n",
    "this was a pain, it would be better if i ACTUALL knew scala i guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6698b2c2b3b46e2987339da70467d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.rdd.RDD\n",
      "authDF: org.apache.spark.sql.DataFrame = [jdbc_password: string, jdbc_username: string]\n",
      "m: Map[String,Any] = Map(jdbc_password -> fooRiuzg54, jdbc_username -> admin)\n",
      "username: Any = admin\n",
      "password: Any = fooRiuzg54\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "val authDF = spark.read.json(\"hdfs:///.config/creds.json\")\n",
    "val m = authDF.first.getValuesMap[Any](authDF.schema.fieldNames)\n",
    "\n",
    "val username = (m(\"jdbc_username\"))\n",
    "//println(username)\n",
    "val password = (m(\"jdbc_password\"))\n",
    "//println(password)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data from parquet files into dataframe, add extra computed columns for htmid and healpixid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b084aa048d9a4ad28230b8ce7babd93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datafile: String = /user/hive/warehouse/object\n",
      "objDF: org.apache.spark.sql.DataFrame = [deepSourceId: bigint, ra: double ... 234 more fields]\n",
      "newDF: org.apache.spark.sql.DataFrame = [deepSourceId: bigint, ra: double ... 236 more fields]\n"
     ]
    }
   ],
   "source": [
    "val datafile = \"/user/hive/warehouse/object\"\n",
    "val objDF = spark.read.parquet(datafile)\n",
    "\n",
    "val newDF = objDF.withColumn(\"htmid\",HTMUtils.htmidUDF(objDF(\"ra\"),objDF(\"decl\"))).withColumn(\"healpixid\", HEALPixUtils.healpixidUDF(objDF(\"ra\"), objDF(\"decl\")))\n",
    "\n",
    "newDF.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"object_newcols\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'println' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'println' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
