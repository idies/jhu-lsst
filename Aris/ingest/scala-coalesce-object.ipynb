{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>175</td><td>application_1580142637008_0181</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"https://sparkhead-0.sparkhead-svc:8090/proxy/application_1580142637008_0181/\">Link</a></td><td><a target=\"_blank\" href=\"https://storage-0-2.storage-0-svc.filedb.svc.cluster.local:8044/node/containerlogs/container_1580142637008_0181_01_000001/root\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f7bd6d0f34023a8607c3e17ae0c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'name': 'sue-sparkles', 'executorMemory': '12G', 'numExecutors': 10, 'executorCores': 4, 'conf': {'spark.jars': '/system/jar/simpleHTM.jar,/system/jar/jhealpix.jar'}, 'kind': 'spark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>175</td><td>application_1580142637008_0181</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"https://sparkhead-0.sparkhead-svc:8090/proxy/application_1580142637008_0181/\">Link</a></td><td><a target=\"_blank\" href=\"https://storage-0-2.storage-0-svc.filedb.svc.cluster.local:8044/node/containerlogs/container_1580142637008_0181_01_000001/root\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\"name\": \"sue-sparkles\", \"executorMemory\": \"12G\", \"numExecutors\": 10, \n",
    " \"executorCores\": 4,\n",
    " \"conf\": {\"spark.jars\": \"/system/jar/simpleHTM.jar,/system/jar/jhealpix.jar\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa589c68653d45bbb694fb4c9bfd8997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import simple.HTMindex\n",
      "import healpix.jhu.Healpix\n",
      "import org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}\n",
      "import org.apache.spark.sql.functions.udf\n",
      "import java.util.Calendar\n"
     ]
    }
   ],
   "source": [
    "import simple.HTMindex\n",
    "import healpix.jhu.Healpix\n",
    "import org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}\n",
    "import org.apache.spark.sql.functions.udf\n",
    "import java.util.Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241fce0c0ba04cfb87a8c1e2aa99eb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined object HTMUtils\n",
      "defined object HEALPixUtils\n"
     ]
    }
   ],
   "source": [
    "object HTMUtils extends Serializable {\n",
    "    var htmindex= new HTMindex() with Serializable\n",
    "    val htmid: (Double, Double) => Long = htmindex.lookupId(_,_)\n",
    "\n",
    "    val htmidUDF=udf(htmid)\n",
    "    \n",
    "}\n",
    "\n",
    "object HEALPixUtils extends Serializable {\n",
    "    var hp = new Healpix() with Serializable\n",
    "    val healpixid: (Double, Double) => Long = hp.ang2pix(_,_)\n",
    "    val healpixidUDF=udf(healpixid)\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c12b1166ded4025a0c22484a94ef396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello from scala"
     ]
    }
   ],
   "source": [
    "print(\"hello from scala\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# can we get this login thing to work in scala?\n",
    "this was a pain, it would be better if i ACTUALL knew scala i guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09e24051e254c3d9aad05c9b95d9876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import org.apache.spark.rdd.RDD\n",
      "authDF: org.apache.spark.sql.DataFrame = [jdbc_password: string, jdbc_username: string]\n",
      "m: Map[String,Any] = <lazy>\n",
      "username: Any = <lazy>\n",
      "password: Any = <lazy>\n"
     ]
    }
   ],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "val authDF = spark.read.json(\"hdfs:///.config/creds.json\")\n",
    "lazy val m = authDF.first.getValuesMap[Any](authDF.schema.fieldNames)\n",
    "\n",
    "lazy val username = (m(\"jdbc_username\"))\n",
    "//println(username)\n",
    "lazy val password = (m(\"jdbc_password\"))\n",
    "//println(password)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data from parquet files into dataframe, add extra computed columns for htmid and healpixid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ba588d4bc04eacba96cdeea615ac92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datafile: String = /user/hive/warehouse/object_test_newcols\n",
      "objDF: org.apache.spark.sql.DataFrame = [deepSourceId: bigint, ra: double ... 236 more fields]\n"
     ]
    }
   ],
   "source": [
    "val datafile = \"/user/hive/warehouse/object_test_newcols\"\n",
    "val objDF = spark.read.parquet(datafile)\n",
    "\n",
    "//val newDF = objDF.withColumn(\"htmid\",HTMUtils.htmidUDF(objDF(\"ra\"),objDF(\"decl\"))).withColumn(\"healpixid\", HEALPixUtils.healpixidUDF(objDF(\"ra\"), objDF(\"decl\")))\n",
    "\n",
    "//newDF.write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"object_newcols\")\n",
    "\n",
    "//objDF.coalesce(1400).write.format(\"parquet\").mode(\"overwrite\").saveAsTable(\"object_newcols1400\")\n",
    "//rdd.write.partitionBy(\"foo\").mode(\"overwrite\").parquet(vOutputPath)\n",
    "\n",
    "objDF.write.partitionBy(\"chunkId\").mode(\"overwrite\").format(\"parquet\").saveAsTable(\"obj_test_chunkid\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark",
   "language": "",
   "name": "sparkkernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
