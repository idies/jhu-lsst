{
    "metadata": {
        "kernelspec": {
            "name": "sparkkernel",
            "display_name": "Spark | Scala"
        },
        "language_info": {
            "name": "scala",
            "mimetype": "text/x-scala",
            "codemirror_mode": "text/x-scala",
            "pygments_lexer": "scala"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "Step 1: create DB on master instance (run this one on the SQL kernel)"
            ],
            "metadata": {
                "azdata_cell_guid": "f6f8829f-7085-4697-8672-de31be8f35c3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "\r\n",
                "USE master\r\n",
                "IF EXISTS(select * from sys.databases where name='TwitterData')\r\n",
                "DROP DATABASE TwitterData;\r\n",
                "GO\r\n",
                "CREATE DATABASE TwitterData;\r\n",
                "GO\r\n",
                "USE TwitterData;\r\n",
                "GO\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "6c524158-de3f-40c1-9778-bc1b5304ad6e"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "Step 2: switch to scala context and import packages\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "77692a6e-61fa-4978-8770-5522afff246e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import java.io.{BufferedReader, File, FileNotFoundException, InputStream, InputStreamReader}\r\n",
                "import java.net.URLEncoder\r\n",
                "import java.nio.charset.StandardCharsets\r\n",
                "import java.util.Base64\r\n",
                "import javax.crypto.Mac\r\n",
                "import javax.crypto.spec.SecretKeySpec\r\n",
                "import scala.collection.JavaConverters._\r\n",
                "import org.apache.commons.io.IOUtils\r\n",
                "import org.apache.http.client.methods.HttpGet\r\n",
                "import org.apache.http.impl.client.CloseableHttpClient\r\n",
                "import org.apache.http.impl.client.HttpClients\r\n",
                "import org.apache.hadoop.conf.Configuration\r\n",
                "import org.apache.hadoop.fs.FileSystem\r\n",
                "import org.apache.hadoop.fs.Path\r\n",
                "import java.io.PrintWriter\r\n",
                "import org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}"
            ],
            "metadata": {
                "azdata_cell_guid": "6aa98d1a-ee9a-4404-b34b-24acdafdf832"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Starting Spark application\n",
                    "output_type": "stream"
                },
                {
                    "data": {
                        "text/plain": "<IPython.core.display.HTML object>",
                        "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>35</td><td>application_1568670927228_0038</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"https://172.23.25.58:30443/gateway/default/yarn/proxy/application_1568670927228_0038/\">Link</a></td><td><a target=\"_blank\" href=\"https://172.23.25.58:30443/gateway/default/yarn/container/container_1568670927228_0038_01_000001/root\">Link</a></td><td>âœ”</td></tr></table>"
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "text": "SparkSession available as 'spark'.\n",
                    "output_type": "stream"
                },
                {
                    "name": "stdout",
                    "text": "import java.io.{BufferedReader, File, FileNotFoundException, InputStream, InputStreamReader}\nimport java.net.URLEncoder\nimport java.nio.charset.StandardCharsets\nimport java.util.Base64\nimport javax.crypto.Mac\nimport javax.crypto.spec.SecretKeySpec\nimport scala.collection.JavaConverters._\nimport org.apache.commons.io.IOUtils\nimport org.apache.http.client.methods.HttpGet\nimport org.apache.http.impl.client.CloseableHttpClient\nimport org.apache.http.impl.client.HttpClients\nimport org.apache.hadoop.conf.Configuration\nimport org.apache.hadoop.fs.FileSystem\nimport org.apache.hadoop.fs.Path\nimport java.io.PrintWriter\nimport org.apache.spark.sql.{SparkSession, SaveMode, Row, DataFrame}\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "setup stuff\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "2d1f7ee9-27de-4a02-9e0c-69203a67db40"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "//Twitter api auth keys\r\n",
                "val consumerKey = \"7SMW41Vb3dLfZkWsFYxGa8Mdo\"\r\n",
                "val consumerSecret = \"08pEiMTXY0xyv1TDfUwBYJiNzEOupoVwaw9Vk3tzt1gvsZq9QF\"\r\n",
                "val accessToken = \"10022462-hx6lkyAGKLnGU8GhOHpIUfyRpGhosiph491oY7J6k\"\r\n",
                "val accessTokenSecret = \"avduKmDt6dlL8GzWLRCorTCLTFrAydr43GsjGPHQn3fhT\"\r\n",
                "\r\n",
                "//SQL auth stuff\r\n",
                "val user = \"sa\"\r\n",
                "val password = \"fooRiuzg54\"\r\n",
                "\r\n",
                "//Spark-SQL connector params\r\n",
                "val hostname = \"master-0.master-svc\"\r\n",
                "val port = 1433\r\n",
                "val database = \"TwitterData\"\r\n",
                "val url = s\"jdbc:sqlserver://${hostname}:${port};database=${database};user={$user};password=${password};\"\r\n",
                "val dbtable = \"Tweets\"\r\n",
                "val datasource_name = \"TweetsDataSource\"\r\n",
                "\r\n",
                "//Twitter stream object parameters\r\n",
                "\r\n",
                "val filters = Array(\"goose\", \"springsteen\", \"punk\", \"hypnospace\")  \r\n",
                "val path = \"/user/twitter/\"\r\n",
                "val savingInterval = 2000\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "9355e2fd-b84e-4327-b133-c7c38245e94e"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "consumerKey: String = 7SMW41Vb3dLfZkWsFYxGa8Mdo\nconsumerSecret: String = 08pEiMTXY0xyv1TDfUwBYJiNzEOupoVwaw9Vk3tzt1gvsZq9QF\naccessToken: String = 10022462-hx6lkyAGKLnGU8GhOHpIUfyRpGhosiph491oY7J6k\naccessTokenSecret: String = avduKmDt6dlL8GzWLRCorTCLTFrAydr43GsjGPHQn3fhT\nuser: String = sa\npassword: String = fooRiuzg54\nhostname: String = master-0.master-svc\nport: Int = 1433\ndatabase: String = TwitterData\nurl: String = jdbc:sqlserver://master-0.master-svc:1433;database=TwitterData;user={sa};password=fooRiuzg54;\ndbtable: String = Tweets\ndatasource_name: String = TweetsDataSource\nfilters: Array[String] = Array(goose, springsteen, punk, hypnospace)\npath: String = /user/twitter/\nsavingInterval: Int = 2000\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "code",
            "source": [
                "//this is test stuff, don't run it unless you started the stream already\r\n",
                "twitterStream.isDownloading"
            ],
            "metadata": {
                "azdata_cell_guid": "00504bcc-d2fc-4ad0-b4d0-224569446834"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "<console>:43: error: not found: value twitterStream\n       twitterStream.isDownloading\n       ^\n\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 7
        },
        {
            "cell_type": "code",
            "source": [
                "\r\n",
                "class TwitterStream(\r\n",
                "  consumerKey: String,\r\n",
                "  consumerSecret: String,\r\n",
                "  accessToken: String,\r\n",
                "  accessTokenSecret: String,\r\n",
                "  path: String,\r\n",
                "  savingInterval: Long,\r\n",
                "  filters: Array[String]) {\r\n",
                "  \r\n",
                "  private val threadName = \"tweet-downloader\"\r\n",
                "  \r\n",
                "  {\r\n",
                "    val hasActiveStream = Thread.getAllStackTraces().keySet().asScala.map(_.getName).contains(threadName)\r\n",
                "    if (hasActiveStream) {\r\n",
                "      throw new RuntimeException(\r\n",
                "        \"There is already an active stream that writes tweets to the configured path. \" +\r\n",
                "        \"Please stop the existing stream first (using twitterStream.stop()).\")\r\n",
                "    }\r\n",
                "  }\r\n",
                "  \r\n",
                "  @volatile private var thread: Thread = null\r\n",
                "  @volatile private var isStopped = false\r\n",
                "  @volatile var isDownloading = false\r\n",
                "  @volatile var exception: Throwable = null\r\n",
                "\r\n",
                "  private var httpclient: CloseableHttpClient = null\r\n",
                "  private var input: InputStream = null\r\n",
                "  private var httpGet: HttpGet = null\r\n",
                "  \r\n",
                "  private def encode(string: String): String = {\r\n",
                "    URLEncoder.encode(string, StandardCharsets.UTF_8.name)\r\n",
                "  }\r\n",
                "\r\n",
                "  def start(): Unit = synchronized {\r\n",
                "    isDownloading = false\r\n",
                "    isStopped = false\r\n",
                "    thread = new Thread(threadName) {\r\n",
                "      override def run(): Unit = {\r\n",
                "        httpclient = HttpClients.createDefault()\r\n",
                "        try {\r\n",
                "          requestStream(httpclient)\r\n",
                "        } catch {\r\n",
                "          case e: Throwable => exception = e\r\n",
                "        } finally {\r\n",
                "          //TwitterStream.this.stop()\r\n",
                "        }\r\n",
                "      }\r\n",
                "    }\r\n",
                "    thread.start()\r\n",
                "  }\r\n",
                "\r\n",
                "  def requestStream(httpclient: CloseableHttpClient): Unit = {\r\n",
                "    val url = \"https://stream.twitter.com/1.1/statuses/filter.json\"\r\n",
                "    val timestamp = System.currentTimeMillis / 1000\r\n",
                "    val nonce = timestamp + scala.util.Random.nextInt\r\n",
                "    val oauthNonce = nonce.toString\r\n",
                "    val oauthTimestamp = timestamp.toString\r\n",
                "\r\n",
                "    val oauthHeaderParams = List(\r\n",
                "      \"oauth_consumer_key\" -> encode(consumerKey),\r\n",
                "      \"oauth_signature_method\" -> encode(\"HMAC-SHA1\"),\r\n",
                "      \"oauth_timestamp\" -> encode(oauthTimestamp),\r\n",
                "      \"oauth_nonce\" -> encode(oauthNonce),\r\n",
                "      \"oauth_token\" -> encode(accessToken),\r\n",
                "      \"oauth_version\" -> \"1.0\"\r\n",
                "    )\r\n",
                "    val requestParams = List(\r\n",
                "      \"track\" -> encode(filters.mkString(\",\"))\r\n",
                "    )\r\n",
                "\r\n",
                "    val parameters = (oauthHeaderParams ++ requestParams).sortBy(_._1).map(pair => s\"\"\"${pair._1}=${pair._2}\"\"\").mkString(\"&\")\r\n",
                "    val base = s\"GET&${encode(url)}&${encode(parameters)}\"\r\n",
                "    val oauthBaseString: String = base.toString\r\n",
                "    val signature = generateSignature(oauthBaseString)\r\n",
                "    val oauthFinalHeaderParams = oauthHeaderParams ::: List(\"oauth_signature\" -> encode(signature))\r\n",
                "    val authHeader = \"OAuth \" + ((oauthFinalHeaderParams.sortBy(_._1).map(pair => s\"\"\"${pair._1}=\"${pair._2}\"\"\"\")).mkString(\", \"))\r\n",
                "\r\n",
                "    httpGet = new HttpGet(s\"https://stream.twitter.com/1.1/statuses/filter.json?${requestParams.map(pair => s\"\"\"${pair._1}=${pair._2}\"\"\").mkString(\"&\")}\")\r\n",
                "    httpGet.addHeader(\"Authorization\", authHeader)\r\n",
                "    println(\"Downloading tweets!\")\r\n",
                "    val response = httpclient.execute(httpGet)\r\n",
                "    val entity = response.getEntity()\r\n",
                "    input = entity.getContent()\r\n",
                "    if (response.getStatusLine.getStatusCode != 200) {\r\n",
                "      throw new RuntimeException(IOUtils.toString(input, StandardCharsets.UTF_8))\r\n",
                "    }\r\n",
                "    isDownloading = true\r\n",
                "    val reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8))\r\n",
                "    var line: String = null\r\n",
                "    var lineno = 1\r\n",
                "    line = reader.readLine()\r\n",
                "    var lastSavingTime = System.currentTimeMillis()\r\n",
                "    val s = new StringBuilder()\r\n",
                "   \r\n",
                "    val conf = new Configuration()\r\n",
                "    val fs= FileSystem.get(conf)\r\n",
                "                                                                      \r\n",
                "    while (line != null && !isStopped) {\r\n",
                "\r\n",
                "      \r\n",
                "      lineno += 1\r\n",
                "      line = reader.readLine()\r\n",
                "      s.append(line + \"\\n\")\r\n",
                "      val now = System.currentTimeMillis()\r\n",
                "      if (now - lastSavingTime >= savingInterval) {\r\n",
                "\r\n",
                "       \r\n",
                "          \r\n",
                "         val df = spark.read.json(spark.sparkContext.parallelize(Seq(s.toString)))\r\n",
                "         df.write.json(path + now.toString)\r\n",
                "          \r\n",
                "        lastSavingTime = now\r\n",
                "        s.clear()\r\n",
                "      }\r\n",
                "    }\r\n",
                "  }\r\n",
                "\r\n",
                "  private def generateSignature(data: String): String = {\r\n",
                "    val mac = Mac.getInstance(\"HmacSHA1\")\r\n",
                "    val oauthSignature = encode(consumerSecret) + \"&\" + encode(accessTokenSecret)\r\n",
                "    val spec = new SecretKeySpec(oauthSignature.getBytes, \"HmacSHA1\")\r\n",
                "    mac.init(spec)\r\n",
                "    val byteHMAC = mac.doFinal(data.getBytes)\r\n",
                "    return Base64.getEncoder.encodeToString(byteHMAC)\r\n",
                "  }\r\n",
                "\r\n",
                "  def stop(): Unit = synchronized {\r\n",
                "    isStopped = true\r\n",
                "    isDownloading = false\r\n",
                "    try {\r\n",
                "      if (httpGet != null) {\r\n",
                "        httpGet.abort()\r\n",
                "        httpGet = null\r\n",
                "      }\r\n",
                "      if (input != null) {\r\n",
                "        input.close()\r\n",
                "        input = null\r\n",
                "      }\r\n",
                "      if (httpclient != null) {\r\n",
                "        httpclient.close()\r\n",
                "        httpclient = null\r\n",
                "      }\r\n",
                "      if (thread != null) {\r\n",
                "        thread.interrupt()\r\n",
                "        thread = null\r\n",
                "      }\r\n",
                "    } catch {\r\n",
                "      case _: Throwable =>\r\n",
                "    }\r\n",
                "  }\r\n",
                "}\r\n",
                "println(\"class defined\")"
            ],
            "metadata": {
                "azdata_cell_guid": "d5a712aa-5252-4479-bad4-dd89fadc137e"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "warning: there was one deprecation warning; re-run with -deprecation for details\ndefined class TwitterStream\nclass defined\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 8
        },
        {
            "cell_type": "code",
            "source": [
                "val twitterStream = new TwitterStream(consumerKey, consumerSecret, accessToken, accessTokenSecret, path, savingInterval, filters)"
            ],
            "metadata": {
                "azdata_cell_guid": "99bcd360-22d5-4635-b97b-4b95864f2de0"
            },
            "outputs": [],
            "execution_count": 9
        },
        {
            "cell_type": "code",
            "source": [
                "twitterStream.start()\r\n",
                "\r\n",
                "if (twitterStream.exception != null) { throw twitterStream.exception }"
            ],
            "metadata": {
                "azdata_cell_guid": "66ac6f05-606f-40da-91d2-a6ce9a3047e7"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "Downloading tweets!\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 10
        },
        {
            "cell_type": "code",
            "source": [
                "val tweets = spark.read.json(path + \"*\")\r\n",
                "val tweets_schema = tweets.schema\r\n",
                "\r\n",
                "val tweetStream = spark.readStream.\r\n",
                "|schema(tweets_schema).\r\n",
                "|json(path + \"*\").\r\n",
                "|filter($\"lang\" === \"en\").\r\n",
                "|withColumn(\"screen_name\", $\"user.screen_name\").\r\n",
                "|withColumn(\"num_followers\", $\"user.followers_count\").\r\n",
                "|withColumn(\"createdAt\", from_utc_timestamp(from_unixtime(unix_timestamp($\"created_at\", \"EEE MMM dd HH:mm:ss ZZZZ yyyy\")),\"EST\")).\r\n",
                "|select(\"screen_name\",\"createdAt\",\"num_followers\", \"text\")"
            ],
            "metadata": {
                "azdata_cell_guid": "9938e256-26f1-4dd2-ae8f-f6bf86b3245d"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "tweets: org.apache.spark.sql.DataFrame = [created_at: string, display_text_range: array<bigint> ... 29 more fields]\ntweets_schema: org.apache.spark.sql.types.StructType = StructType(StructField(created_at,StringType,true), StructField(display_text_range,ArrayType(LongType,true),true), StructField(entities,StructType(StructField(hashtags,ArrayType(StringType,true),true), StructField(symbols,ArrayType(StringType,true),true), StructField(urls,ArrayType(StructType(StructField(display_url,StringType,true), StructField(expanded_url,StringType,true), StructField(indices,ArrayType(LongType,true),true), StructField(url,StringType,true)),true),true), StructField(user_mentions,ArrayType(StructType(StructField(id,LongType,true), StructField(id_str,StringType,true), StructField(indices,ArrayType(LongType,true),true), StructField(name,StringType,true), StructField(screen_name,StringType,true)),true),true)),true), ...tweetStream: org.apache.spark.sql.DataFrame = [screen_name: string, createdAt: timestamp ... 2 more fields]\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 11
        },
        {
            "cell_type": "code",
            "source": [
                "\r\n",
                "val query = tweetStream.writeStream.outputMode(\"append\").foreachBatch{ (batchDF: DataFrame, batchId: Long) => \r\n",
                "                batchDF.write\r\n",
                "                    .format(\"com.microsoft.sqlserver.jdbc.spark\")\r\n",
                "                    .mode(\"append\")\r\n",
                "                    .option(\"url\", url)\r\n",
                "                    .option(\"dbtable\", dbtable)\r\n",
                "                    .option(\"user\", user)\r\n",
                "                    .option(\"password\", password)\r\n",
                "                    .option(\"dataPoolDataSource\",datasource_name).save()\r\n",
                "               }.start()\r\n",
                "query.processAllAvailable()\r\n",
                "//query.awaitTermination(40000)"
            ],
            "metadata": {
                "azdata_cell_guid": "07079984-de6c-496a-94b0-18964b618b67"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "text": "query: org.apache.spark.sql.streaming.StreamingQuery = org.apache.spark.sql.execution.streaming.StreamingQueryWrapper@33787315\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 12
        },
        {
            "cell_type": "code",
            "source": [
                "def df_read(dbtable: String,\r\n",
                "                url: String,\r\n",
                "                dataPoolDataSource: String=\"\"): DataFrame = {\r\n",
                "                spark.read\r\n",
                "                        .format(\"com.microsoft.sqlserver.jdbc.spark\")\r\n",
                "                        .option(\"url\", url)\r\n",
                "                        .option(\"dbtable\", dbtable)\r\n",
                "                        .option(\"user\", user)\r\n",
                "                        .option(\"password\", password)\r\n",
                "                        .option(\"dataPoolDataSource\", datasource_name)\r\n",
                "                        .load()\r\n",
                "                }"
            ],
            "metadata": {
                "azdata_cell_guid": "67ca8852-999f-46b9-8666-abb95225b3be"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "\r\n",
                "val new_df = df_read(dbtable, url, dataPoolDataSource=datasource_name)\r\n",
                "new_df.count"
            ],
            "metadata": {
                "azdata_cell_guid": "c14c12bf-1b02-4b28-a71b-ff4035cde371"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "\r\n",
                "twitterStream.stop()"
            ],
            "metadata": {
                "azdata_cell_guid": "53bdb83e-2a42-45b7-80d5-6bf4a793d557"
            },
            "outputs": [
                {
                    "name": "stderr",
                    "text": "An error was encountered:\nInvalid status code '404' from https://172.23.25.58:30443/gateway/default/livy/v1/sessions/35 with error payload: {\"msg\":\"Session '35' not found.\"}\n",
                    "output_type": "stream"
                }
            ],
            "execution_count": 13
        }
    ]
}