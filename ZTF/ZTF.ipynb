{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\"name\": \"gerard-ztf-query\", \"executorMemory\": \"12G\", \"numExecutors\": 16, \"executorCores\": 4,\n",
    " \"conf\": {\"spark.yarn.appMasterEnv.PYSPARK_PYTHON\":\"python3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_hdfs(dir):\n",
    "    cmd = '/opt/hadoop/bin/hdfs dfs -ls {}'.format(dir)\n",
    "    return subprocess.check_output(\n",
    "        cmd,\n",
    "        stderr = subprocess.STDOUT,\n",
    "        shell=True).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "hdfs_dir = 'hdfs:///ztf'\n",
    "print(list_hdfs(hdfs_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "ztf = spark.read.parquet('hdfs:///ztf/full_subset.parquet')#hdfs_dir)# .cache(), data size is too large for cluster to cache\n",
    "ztf.createOrReplaceTempView('ztf')\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "spark.sql('SELECT count(*) FROM ztf').show()\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "spark.sql('SELECT count(*) FROM ztf').show()\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "df = spark.sql('SELECT * FROM ztf where cardinality(mag_r)>30 limit 10 ')#.show()\n",
    "print(time.time()-t)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls=df.select('mjd_r','mag_r').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "for i,row in ls.iterrows():\n",
    "    x=row['mjd_r']\n",
    "    y=row['mag_r']\n",
    "#     a=ax.plot(x,y,\"-o\");\n",
    "    y=[i for _,i in sorted(zip(x,y))]\n",
    "    a=ax.plot(sorted(x),y,\"-o\");\n",
    "    break\n",
    "%matplot plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "spark.sql('SELECT ps1_objid, count(*) as num FROM ztf GROUP BY ps1_objid order by num desc, ps1_objid limit 100').show()\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "df=spark.sql('SELECT mjd_r, mag_r FROM ztf where array_min(mag_r)< 17 limit 10')\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "spark.sql('SELECT mjd_r, mag_r FROM ztf WHERE ps1_objid=132002123692096071').show()\n",
    "print(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "df = spark.sql('SELECT cardinality(mag_r) as card, count(*) as num FROM ztf group by card ')#.show()\n",
    "print(time.time()-t)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
